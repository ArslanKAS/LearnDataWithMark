# Mixtral vs Mistral 7B with Ollama

Comparing the text generated by [Mixtral](https://ollama.ai/library/mixtral) and [Mistral 7B](https://ollama.ai/library/mistral) using [Ollama](https://ollama.ai/)

## Summarising an article

```bash
ollama run mistral --verbose \
  "Can you summarise this article in one bullet point $(cat data/ai_supreme_court.txt)"
```

```bash
ollama run mixtral --verbose \
  "Can you summarise this article in one bullet point $(cat data/ai_supreme_court.txt)"
```

## Detecting sentiment

```bash
ollama run mistral --verbose \
  "Can you tell me the sentiment of the following piece of text. Return only 'POSITIVE' or 'NEGATIVE': $(cat data/linkedin.txt)"
```

```bash
ollama run mixtral --verbose \
  "Can you tell me the sentiment of the following piece of text. Return only 'POSITIVE' or 'NEGATIVE': $(cat data/linkedin.txt)"
```

## Suggesting prompts

```bash
ollama run mistral --verbose \
  "Can you suggest some prompts to help me review this book for myself? $(cat data/book.txt)"
```

```bash
ollama run mixtral --verbose \
  "Can you suggest some prompts to help me review this book for myself? $(cat data/book.txt)"
```

## Updating code

```bash
ollama run mistral --verbose \
  "How can I limit the number of Dask concurrent threads? $(cat data/code.py)"
```

```bash
ollama run mixtral --verbose \
  "How can I limit the number of Dask concurrent threads? $(cat data/code.py)"
```
